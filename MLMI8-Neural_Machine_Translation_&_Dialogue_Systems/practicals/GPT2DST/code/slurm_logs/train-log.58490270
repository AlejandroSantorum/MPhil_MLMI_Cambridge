JobID: 58490270
======
Time: Wed  6 Apr 15:45:36 BST 2022
Running on master node: gpu-q-50
2022-04-06 15:47 - __main__ - INFO - Restarting training from checkpoint: /rds/project/rds-xyBFuSj0hm0/MLMI8.L2022/GPT2DST/checkpoints/nlu_flat_start/model.60000
2022-04-06 15:47 - __main__ - INFO - data:
  version: 1
  processing:
    sequence_format:
      separators:
        state_components: ' <sep> '
      example_format:
        dst_input: turn_pair
        belief_state_type: nlu
train:
  model_name_or_path: gpt2
  max_seq_len: 1024
  epochs: 4
  data_size: -1
  batch_size: 1
  gradient_accumulation_steps: 8
  max_grad_norm: 1.0
  use_scheduler: true
  warmup_steps: 0
  learning_rate: 6.25e-05
  adam_eps: 1.0e-12
  fp16: false
  eps: 1.0e-12
  checkpoint_dir: checkpoints
  experiment_name: nlu_continued_training
  checkpoint: ''
  verbose:
    disable_display: false
dev:
  max_seq_len: 1024
  data_size: -1
  eval_interval: 2000
  batch_size: 1
  verbose:
    disable_display: false
reproduce:
  seed: 1122
  cudnn:
    enabled: true
    deterministic: false
    benchmark: true

2022-04-06 15:47 - __main__ - INFO - Training on: GPU
2022-04-06 15:47 - utils - INFO - Load model, tokenizer from /rds/project/rds-xyBFuSj0hm0/MLMI8.L2022/GPT2DST/checkpoints/nlu_flat_start/model.60000
2022-04-06 15:47 - __main__ - INFO - Tensorboard logs saved at: /rds/user/as3159/hpc-work/runs/nlu_continued_training
2022-04-06 15:47 - dstdataset - INFO - Data Statistics: /rds/project/rds-xyBFuSj0hm0/MLMI8.L2022/GPT2DST/data_preparation/data/multiwoz21/processed/train/version_1/data.json -> 54971 examples
2022-04-06 15:47 - dstdataset - INFO - Data Statistics: /rds/project/rds-xyBFuSj0hm0/MLMI8.L2022/GPT2DST/data_preparation/data/multiwoz21/processed/dev/version_1/data.json -> 7374 examples
2022-04-06 15:48 - __main__ - INFO - Epoch: 60000 | dev loss: 0.20932798 | time: 65.943
2022-04-06 15:48 - __main__ - INFO - Start training!
2022-04-06 15:57 - __main__ - INFO - Epoch: 0 | Batch: 80000 | devel loss: 0.23229891 | time: 65.413
2022-04-06 15:57 - utils - INFO - Save model in checkpoints/nlu_continued_training/model.80000!
2022-04-06 16:06 - __main__ - INFO - Epoch: 0 | Batch: 100000 | devel loss: 0.20311062 | time: 65.791
2022-04-06 16:06 - utils - INFO - Save model in checkpoints/nlu_continued_training/model.100000!
2022-04-06 16:12 - __main__ - INFO - Epoch: 0 | Batch: 114971 | train loss: 0.23251866 | time: 1433.522
2022-04-06 16:13 - __main__ - INFO - Epoch: 0 | Batch: 114971 | devel loss: 0.21118396 | time: 65.068
2022-04-06 16:13 - utils - INFO - Save model in checkpoints/nlu_continued_training/model.114971!
2022-04-06 16:16 - __main__ - INFO - Epoch: 1 | Batch: 120000 | devel loss: 0.22544434 | time: 65.024
2022-04-06 16:16 - utils - INFO - Save model in checkpoints/nlu_continued_training/model.120000!
2022-04-06 16:25 - __main__ - INFO - Epoch: 1 | Batch: 140000 | devel loss: 0.20875389 | time: 65.741
2022-04-06 16:25 - utils - INFO - Save model in checkpoints/nlu_continued_training/model.140000!
2022-04-06 16:34 - __main__ - INFO - Epoch: 1 | Batch: 160000 | devel loss: 0.22846196 | time: 65.732
2022-04-06 16:34 - utils - INFO - Save model in checkpoints/nlu_continued_training/model.160000!
2022-04-06 16:38 - __main__ - INFO - Epoch: 1 | Batch: 169942 | train loss: 0.19158934 | time: 1486.511
2022-04-06 16:39 - __main__ - INFO - Epoch: 1 | Batch: 169942 | devel loss: 0.21047864 | time: 65.714
2022-04-06 16:39 - utils - INFO - Save model in checkpoints/nlu_continued_training/model.169942!
2022-04-06 16:44 - __main__ - INFO - Epoch: 2 | Batch: 180000 | devel loss: 0.24537103 | time: 65.622
2022-04-06 16:44 - utils - INFO - Save model in checkpoints/nlu_continued_training/model.180000!
2022-04-06 16:53 - __main__ - INFO - Epoch: 2 | Batch: 200000 | devel loss: 0.28658600 | time: 66.042
2022-04-06 16:53 - utils - INFO - Save model in checkpoints/nlu_continued_training/model.200000!
2022-04-06 17:02 - __main__ - INFO - Epoch: 2 | Batch: 220000 | devel loss: 0.24167622 | time: 65.698
2022-04-06 17:02 - utils - INFO - Save model in checkpoints/nlu_continued_training/model.220000!
2022-04-06 17:04 - __main__ - INFO - Epoch: 2 | Batch: 224913 | train loss: 0.15651679 | time: 1489.736
2022-04-06 17:05 - __main__ - INFO - Epoch: 2 | Batch: 224913 | devel loss: 0.25037567 | time: 65.539
2022-04-06 17:05 - utils - INFO - Save model in checkpoints/nlu_continued_training/model.224913!
2022-04-06 17:12 - __main__ - INFO - Epoch: 3 | Batch: 240000 | devel loss: 0.27539327 | time: 65.334
2022-04-06 17:12 - utils - INFO - Save model in checkpoints/nlu_continued_training/model.240000!
2022-04-06 17:21 - __main__ - INFO - Epoch: 3 | Batch: 260000 | devel loss: 0.29186307 | time: 64.863
2022-04-06 17:21 - utils - INFO - Save model in checkpoints/nlu_continued_training/model.260000!
2022-04-06 17:29 - __main__ - INFO - Epoch: 3 | Batch: 279884 | train loss: 0.12163622 | time: 1420.994
2022-04-06 17:30 - __main__ - INFO - Epoch: 3 | Batch: 279884 | devel loss: 0.30175453 | time: 65.465
2022-04-06 17:30 - utils - INFO - Save model in checkpoints/nlu_continued_training/model.279884!
2022-04-06 17:30 - __main__ - INFO - lowest dev loss: 0.20311062091301027 | step: 100000 | time: 65.7907645702362.
2022-04-06 17:30 - __main__ - INFO - This is GPT2 for MultiWOZ DST!
Time: Wed  6 Apr 17:30:23 BST 2022
