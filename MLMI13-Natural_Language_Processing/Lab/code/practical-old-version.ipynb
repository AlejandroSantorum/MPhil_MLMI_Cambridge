{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Corpora import MovieReviewCorpus\n",
    "from Lexicon import SentimentLexicon\n",
    "from Statistics import SignTest\n",
    "from Classifiers import NaiveBayesText, SVMText\n",
    "from Extensions import SVMDoc2Vec\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- classifying reviews using sentiment lexicon  ---\n",
      "token-only results: 0.67\n",
      "magnitude results: 0.68\n",
      "magnitude lexicon results are not significant with respect to token-only\n"
     ]
    }
   ],
   "source": [
    "# retrieve corpus\n",
    "corpus=MovieReviewCorpus(stemming=False,pos=False)\n",
    "\n",
    "# use sign test for all significance testing\n",
    "signTest=SignTest()\n",
    "\n",
    "print(\"--- classifying reviews using sentiment lexicon  ---\")\n",
    "\n",
    "# read in lexicon\n",
    "lexicon=SentimentLexicon()\n",
    "\n",
    "# on average there are more positive than negative words per review\n",
    "# (~7.13 more positive than negative per review)\n",
    "# to take this bias into account will use threshold (roughly the bias itself)\n",
    "# to make it harder to classify as positive\n",
    "threshold=8\n",
    "\n",
    "# question 0.1\n",
    "lexicon.classify(corpus.reviews,threshold,magnitude=False)\n",
    "token_preds=lexicon.predictions\n",
    "print(f\"token-only results: {lexicon.getAccuracy():.2f}\")\n",
    "\n",
    "lexicon.classify(corpus.reviews,threshold,magnitude=True)\n",
    "magnitude_preds=lexicon.predictions\n",
    "print(f\"magnitude results: {lexicon.getAccuracy():.2f}\")\n",
    "\n",
    "# question 0.2\n",
    "p_value=signTest.getSignificance(token_preds,magnitude_preds)\n",
    "significance = \"significant\" if p_value < 0.05 else \"not significant\"\n",
    "print(f\"magnitude lexicon results are {significance} with respect to token-only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- classifying reviews using Naive Bayes on held-out test set ---\n",
      "Accuracy without smoothing: 0.46\n"
     ]
    }
   ],
   "source": [
    "# question 1.0\n",
    "print(\"--- classifying reviews using Naive Bayes on held-out test set ---\")\n",
    "NB=NaiveBayesText(smoothing=False,bigrams=False,trigrams=False,discard_closed_class=False)\n",
    "NB.train(corpus.train)\n",
    "NB.test(corpus.test)\n",
    "# store predictions from classifier\n",
    "non_smoothed_preds=NB.predictions\n",
    "print(f\"Accuracy without smoothing: {NB.getAccuracy():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using smoothing: 0.82\n",
      "results using smoothing are significant with respect to no smoothing\n"
     ]
    }
   ],
   "source": [
    "# question 2.0\n",
    "# use smoothing\n",
    "NB=NaiveBayesText(smoothing=True,bigrams=False,trigrams=False,discard_closed_class=False)\n",
    "NB.train(corpus.train)\n",
    "NB.test(corpus.test)\n",
    "smoothed_preds=NB.predictions\n",
    "# saving this for use later\n",
    "num_non_stemmed_features=len(NB.vocabulary)\n",
    "print(f\"Accuracy using smoothing: {NB.getAccuracy():.2f}\")\n",
    "\n",
    "\n",
    "# question 2.1\n",
    "# see if smoothing significantly improves results\n",
    "p_value=signTest.getSignificance(non_smoothed_preds,smoothed_preds)\n",
    "significance = \"significant\" if p_value < 0.05 else \"not significant\"\n",
    "print(f\"results using smoothing are {significance} with respect to no smoothing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- classifying reviews using 10-fold cross-evaluation ---\n",
      "Accuracy: 0.810\n",
      "Std. Dev: 0.020736441353327688\n"
     ]
    }
   ],
   "source": [
    "# question 3.0\n",
    "print(\"--- classifying reviews using 10-fold cross-evaluation ---\")\n",
    "# using previous instantiated object\n",
    "NB.crossValidate(corpus)\n",
    "# using cross-eval for smoothed predictions from now on\n",
    "smoothed_preds=NB.predictions\n",
    "print(f\"Accuracy: {NB.getAccuracy():.3f}\")\n",
    "print(f\"Std. Dev: {NB.getStdDeviation()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- stemming corpus ---\n",
      "--- cross-validating NB using stemming ---\n",
      "Accuracy: 0.814\n",
      "Std. Dev: 0.026\n",
      "results using stemming are not significant with respect to non-stemmed corpus\n",
      "--- determining the number of features before/after stemming ---\n",
      "Number of features before stemming: 52555\n",
      "Number of features after stemming: 32404\n"
     ]
    }
   ],
   "source": [
    "# question 4.0\n",
    "print(\"--- stemming corpus ---\")\n",
    "# retrieve corpus with tokenized text and stemming (using porter)\n",
    "stemmed_corpus=MovieReviewCorpus(stemming=True,pos=False)\n",
    "print(\"--- cross-validating NB using stemming ---\")\n",
    "NB.crossValidate(stemmed_corpus)\n",
    "stemmed_preds=NB.predictions\n",
    "print(f\"Accuracy: {NB.getAccuracy():.3f}\")\n",
    "print(f\"Std. Dev: {NB.getStdDeviation():.3f}\")\n",
    "\n",
    "# TODO Q4.1\n",
    "# see if stemming significantly improves results on smoothed NB\n",
    "p_value=signTest.getSignificance(stemmed_preds,smoothed_preds)\n",
    "significance = \"significant\" if p_value < 0.05 else \"not significant\"\n",
    "print(f\"results using stemming are {significance} with respect to non-stemmed corpus\")\n",
    "\n",
    "# TODO Q4.2\n",
    "print(\"--- determining the number of features before/after stemming ---\")\n",
    "print(\"Number of features before stemming:\", num_non_stemmed_features)\n",
    "NB.train(stemmed_corpus.train)\n",
    "print(\"Number of features after stemming:\", len(NB.vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- cross-validating naive bayes using smoothing and bigrams ---\n",
      "Accuracy: 0.76\n",
      "Std. Dev: 0.02\n",
      "results using smoothing and bigrams are significant with respect to smoothing only\n",
      "--- cross-validating naive bayes using smoothing and trigrams ---\n",
      "Accuracy: 0.70\n",
      "Std. Dev: 0.03\n",
      "results using smoothing and trigrams are significant with respect to smoothing only\n",
      "--- determining the number of features before/after using bigrams ---\n",
      "Number of features before using bigrams (Q3): 52555\n",
      "Number of features after using bigrams: 500086\n",
      "Number of features after using trigrams: 1015074\n"
     ]
    }
   ],
   "source": [
    "# question Q5.0\n",
    "\n",
    "# cross-validate model using smoothing and bigrams\n",
    "print(\"--- cross-validating naive bayes using smoothing and bigrams ---\")\n",
    "NB=NaiveBayesText(smoothing=True,bigrams=True,trigrams=False,discard_closed_class=False)\n",
    "NB.crossValidate(corpus)\n",
    "smoothed_and_bigram_preds=NB.predictions\n",
    "print(f\"Accuracy: {NB.getAccuracy():.2f}\") \n",
    "print(f\"Std. Dev: {NB.getStdDeviation():.2f}\")\n",
    "\n",
    "# counting features using bigrams\n",
    "NB.train(corpus.train)\n",
    "num_bigram_features = len(NB.vocabulary)\n",
    "\n",
    "# see if bigrams significantly improves results on smoothed NB only\n",
    "p_value=signTest.getSignificance(smoothed_preds,smoothed_and_bigram_preds)\n",
    "signifance = \"significant\" if p_value < 0.05 else \"not significant\"\n",
    "print(f\"results using smoothing and bigrams are {signifance} with respect to smoothing only\")\n",
    "print(\"--- cross-validating naive bayes using smoothing and trigrams ---\")\n",
    "NB=NaiveBayesText(smoothing=True,bigrams=False,trigrams=True,discard_closed_class=False)\n",
    "NB.crossValidate(corpus)\n",
    "smoothed_and_trigram_preds=NB.predictions\n",
    "print(f\"Accuracy: {NB.getAccuracy():.2f}\") \n",
    "print(f\"Std. Dev: {NB.getStdDeviation():.2f}\")\n",
    "\n",
    "# counting features using trigrams\n",
    "NB.train(corpus.train)\n",
    "num_trigram_features = len(NB.vocabulary)\n",
    "\n",
    "# see if bigrams significantly improves results on smoothed NB only\n",
    "p_value=signTest.getSignificance(smoothed_preds,smoothed_and_trigram_preds)\n",
    "signifance = \"significant\" if p_value < 0.05 else \"not significant\"\n",
    "print(f\"results using smoothing and trigrams are {signifance} with respect to smoothing only\")\n",
    "\n",
    "# TODO Q5.1\n",
    "print(\"--- determining the number of features before/after using bigrams ---\")\n",
    "print(\"Number of features before using bigrams (Q3):\", num_non_stemmed_features)\n",
    "print(\"Number of features after using bigrams:\", num_bigram_features)\n",
    "print(\"Number of features after using trigrams:\", num_trigram_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- classifying reviews using SVM 10-fold cross-eval ---\n",
      "Accuracy: 0.8380\n",
      "Std. Dev: 0.020\n",
      "results using SVMs are not significant with respect to smoothed Naive-Bayes\n"
     ]
    }
   ],
   "source": [
    "# TODO Q6 and 6.1\n",
    "\n",
    "# retrieve corpus\n",
    "corpus=MovieReviewCorpus(stemming=False,pos=False)\n",
    "\n",
    "print(\"--- classifying reviews using SVM 10-fold cross-eval ---\")\n",
    "SVM=SVMText(bigrams=False,trigrams=False,discard_closed_class=False)\n",
    "SVM.crossValidate(corpus)\n",
    "svm_preds=SVM.predictions\n",
    "print(f\"Accuracy: {SVM.getAccuracy():.4f}\") \n",
    "print(f\"Std. Dev: {SVM.getStdDeviation():.3f}\")\n",
    "\n",
    "# see if stemming significantly improves results on smoothed NB\n",
    "p_value=signTest.getSignificance(svm_preds, smoothed_preds)\n",
    "significance = \"significant\" if p_value < 0.05 else \"not significant\"\n",
    "print(f\"results using SVMs are {significance} with respect to smoothed Naive-Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- adding in POS information to corpus ---\n",
      "--- training svm on word+pos features ----\n",
      "Accuracy: 0.8345\n",
      "Std. Dev: 0.026\n",
      "results using Word+POS features with SVMs are not significant with respect to smoothed Naive-Bayes\n",
      "--- training svm discarding closed-class words ---\n",
      "Accuracy: 0.8360\n",
      "Std. Dev: 0.023\n",
      "results discarding all closed-class words are not significant with respect to smoothed Naive-Bayes\n"
     ]
    }
   ],
   "source": [
    "# TODO Q7\n",
    "\n",
    "print(\"--- adding in POS information to corpus ---\")\n",
    "# retrieve corpus with POS information\n",
    "corpus_pos = MovieReviewCorpus(stemming=False,pos=True)\n",
    "\n",
    "print(\"--- training svm on word+pos features ----\")\n",
    "SVM=SVMText(bigrams=False,trigrams=False,discard_closed_class=False)\n",
    "SVM.crossValidate(corpus_pos)\n",
    "svm_wordpos_preds = SVM.predictions\n",
    "print(f\"Accuracy: {SVM.getAccuracy():.4f}\") \n",
    "print(f\"Std. Dev: {SVM.getStdDeviation():.3f}\")\n",
    "\n",
    "# see if stemming significantly improves results on smoothed NB\n",
    "p_value=signTest.getSignificance(svm_wordpos_preds, smoothed_preds)\n",
    "significance = \"significant\" if p_value < 0.05 else \"not significant\"\n",
    "print(f\"results using Word+POS features with SVMs are {significance} with respect to smoothed Naive-Bayes\")\n",
    "\n",
    "print(\"--- training svm discarding closed-class words ---\")\n",
    "SVM_dcc=SVMText(bigrams=False,trigrams=False,discard_closed_class=True)\n",
    "SVM_dcc.crossValidate(corpus_pos)\n",
    "svm_dcc_preds = SVM_dcc.predictions \n",
    "print(f\"Accuracy: {SVM_dcc.getAccuracy():.4f}\") \n",
    "print(f\"Std. Dev: {SVM_dcc.getStdDeviation():.3f}\")\n",
    "\n",
    "# see if stemming significantly improves results on smoothed NB\n",
    "p_value=signTest.getSignificance(svm_dcc_preds, smoothed_preds)\n",
    "significance = \"significant\" if p_value < 0.05 else \"not significant\"\n",
    "print(f\"results discarding all closed-class words are {significance} with respect to smoothed Naive-Bayes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8 (40% of the marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- reading dataset from keras.datasets ---\n",
      "--- getting vocabulary ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- reading dataset from keras.datasets ---\")\n",
    "imdb = tf.keras.datasets.imdb\n",
    "(train_reviews, train_labels), (test_reviews, test_labels) = imdb.load_data()\n",
    "\n",
    "print(\"--- getting vocabulary ---\")\n",
    "vocab_word_to_id = imdb.get_word_index()\n",
    "vocab_word_to_id = {word:(word_id + 3) for word, word_id in vocab_word_to_id.items()}\n",
    "vocab_word_to_id[\"<PAD>\"] = 0\n",
    "vocab_word_to_id[\"<START>\"] = 1\n",
    "vocab_word_to_id[\"<UNK>\"] = 2\n",
    "vocab_word_to_id[\"<UNUSED>\"] = 3\n",
    "\n",
    "vocab_id_to_word =  dict([(value, key) for (key, value) in vocab_word_to_id.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_int_review(int_review):\n",
    "    return [vocab_id_to_word.get(id, \"?\") for id in int_review]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- concatenating train and test reviews to infer their embeddings at once ---\n",
      "--- creating documents after decoding reviews ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- concatenating train and test reviews to infer their embeddings at once ---\")\n",
    "reviews = np.concatenate((train_reviews, test_reviews))\n",
    "\n",
    "print(\"--- creating documents after decoding reviews ---\")\n",
    "docs = [TaggedDocument(decode_int_review(int_review), [i]) for i, int_review in enumerate(reviews)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======> Training:  D2V_model_dm_hs_mc1_vs50.model\n",
      "Results of D2V_model_dm_hs_mc1_vs50.model Acc: 0.80716 +- 0.0045622801316885335\n",
      "======> Training:  D2V_model_dm_hs_mc1_vs100.model\n",
      "Results of D2V_model_dm_hs_mc1_vs100.model Acc: 0.81372 +- 0.007193441457327658\n",
      "======> Training:  D2V_model_dm_hs_mc2_vs50.model\n",
      "Results of D2V_model_dm_hs_mc2_vs50.model Acc: 0.79656 +- 0.004999839997439939\n",
      "======> Training:  D2V_model_dm_hs_mc2_vs100.model\n",
      "Results of D2V_model_dm_hs_mc2_vs100.model Acc: 0.8126 +- 0.00466218832738446\n",
      "======> Training:  D2V_model_dm_hs_mc5_vs50.model\n",
      "Results of D2V_model_dm_hs_mc5_vs50.model Acc: 0.79604 +- 0.004455827644781613\n",
      "======> Training:  D2V_model_dm_hs_mc5_vs100.model\n",
      "Results of D2V_model_dm_hs_mc5_vs100.model Acc: 0.80988 +- 0.005924997890294991\n",
      "======> Training:  D2V_model_dm_ns_mc1_vs50.model\n",
      "Results of D2V_model_dm_ns_mc1_vs50.model Acc: 0.8386 +- 0.005411838874172068\n",
      "======> Training:  D2V_model_dm_ns_mc1_vs100.model\n",
      "Results of D2V_model_dm_ns_mc1_vs100.model Acc: 0.85724 +- 0.005161240161046576\n",
      "======> Training:  D2V_model_dm_ns_mc2_vs50.model\n",
      "Results of D2V_model_dm_ns_mc2_vs50.model Acc: 0.83644 +- 0.004679999999999983\n",
      "======> Training:  D2V_model_dm_ns_mc2_vs100.model\n",
      "Results of D2V_model_dm_ns_mc2_vs100.model Acc: 0.85836 +- 0.00409272525342221\n",
      "======> Training:  D2V_model_dm_ns_mc5_vs50.model\n",
      "Results of D2V_model_dm_ns_mc5_vs50.model Acc: 0.84204 +- 0.004150951698104903\n",
      "======> Training:  D2V_model_dm_ns_mc5_vs100.model\n",
      "Results of D2V_model_dm_ns_mc5_vs100.model Acc: 0.85904 +- 0.005289083096340975\n",
      "======> Training:  D2V_model_dbow_hs_mc1_vs50.model\n",
      "Results of D2V_model_dbow_hs_mc1_vs50.model Acc: 0.8772 +- 0.004675040106779842\n",
      "======> Training:  D2V_model_dbow_hs_mc1_vs100.model\n",
      "Results of D2V_model_dbow_hs_mc1_vs100.model Acc: 0.87136 +- 0.006650593958437089\n",
      "======> Training:  D2V_model_dbow_hs_mc2_vs50.model\n",
      "Results of D2V_model_dbow_hs_mc2_vs50.model Acc: 0.87624 +- 0.006352826142749384\n",
      "======> Training:  D2V_model_dbow_hs_mc2_vs100.model\n",
      "Results of D2V_model_dbow_hs_mc2_vs100.model Acc: 0.87024 +- 0.0061766010070264344\n",
      "======> Training:  D2V_model_dbow_hs_mc5_vs50.model\n",
      "Results of D2V_model_dbow_hs_mc5_vs50.model Acc: 0.87792 +- 0.004240000000000003\n",
      "======> Training:  D2V_model_dbow_hs_mc5_vs100.model\n",
      "Results of D2V_model_dbow_hs_mc5_vs100.model Acc: 0.86896 +- 0.006551213628023441\n",
      "======> Training:  D2V_model_dbow_ns_mc1_vs50.model\n",
      "Results of D2V_model_dbow_ns_mc1_vs50.model Acc: 0.89544 +- 0.003907735917382343\n",
      "======> Training:  D2V_model_dbow_ns_mc1_vs100.model\n",
      "Results of D2V_model_dbow_ns_mc1_vs100.model Acc: 0.89768 +- 0.006936973403437549\n",
      "======> Training:  D2V_model_dbow_ns_mc2_vs50.model\n",
      "Results of D2V_model_dbow_ns_mc2_vs50.model Acc: 0.8966 +- 0.006287129710766288\n",
      "======> Training:  D2V_model_dbow_ns_mc2_vs100.model\n",
      "Results of D2V_model_dbow_ns_mc2_vs100.model Acc: 0.896 +- 0.007026805817724012\n",
      "======> Training:  D2V_model_dbow_ns_mc5_vs50.model\n",
      "Results of D2V_model_dbow_ns_mc5_vs50.model Acc: 0.89724 +- 0.005054740349414588\n",
      "======> Training:  D2V_model_dbow_ns_mc5_vs100.model\n",
      "Results of D2V_model_dbow_ns_mc5_vs100.model Acc: 0.89772 +- 0.007401729527617164\n"
     ]
    }
   ],
   "source": [
    "MODEL_STORE_PATH = \"./doc2vec_models/\"\n",
    "base_model_name = \"D2V_model_\"\n",
    "\n",
    "# distributed memory of distributed bag of words\n",
    "for dm in [1,0]:\n",
    "    if dm: dm_model_name = base_model_name+\"dm_\"\n",
    "    else: dm_model_name = base_model_name+\"dbow_\"\n",
    "\n",
    "    # hierarchical softmax or negative sampling\n",
    "    for hs in [1,0]:\n",
    "        if hs:\n",
    "            hs_model_name = dm_model_name+\"hs_\"\n",
    "            neg = 0\n",
    "        else:\n",
    "            hs_model_name = dm_model_name+\"ns_\"\n",
    "            neg = 5\n",
    "        \n",
    "        # ignores all words with total frequency lower than this\n",
    "        for min_count in [1, 2, 5]:\n",
    "            mc_model_name = hs_model_name+\"mc\"+str(min_count)\n",
    "\n",
    "            # embeddings vector size\n",
    "            for vec_size in [50, 100]:\n",
    "                model_name = mc_model_name+\"_vs\"+str(vec_size)+\".model\"\n",
    "\n",
    "                print(\"======> Training: \", model_name)\n",
    "                d2v_model = Doc2Vec(docs, dm=dm, min_count=min_count, vector_size=vec_size,\n",
    "                                    hs=hs, negative=neg, epochs=60, sample=0)\n",
    "                \n",
    "                # storing model\n",
    "                d2v_model.save(MODEL_STORE_PATH+model_name)\n",
    "\n",
    "                # getting embeddings\n",
    "                embeddings = d2v_model.dv.get_normed_vectors()\n",
    "                train_embeddings, test_embeddings = np.split(embeddings, [25000])\n",
    "\n",
    "                # training + testing using a SVM\n",
    "                SVMD2V = SVMDoc2Vec()\n",
    "                SVMD2V.train(train_embeddings, train_labels)\n",
    "                SVMD2V.test(test_embeddings, test_labels)\n",
    "                # results\n",
    "                acc = SVMD2V.getAccuracy()\n",
    "                stdev = SVMD2V.getStdDeviation()\n",
    "\n",
    "                print(\"Results of\", model_name, \"Acc:\", acc, \"+-\", stdev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Do NOT executing next cell** (unless you are sure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- pre-training doc2vec model ---\n"
     ]
    }
   ],
   "source": [
    "# question 8.0\n",
    "print(\"--- pre-training doc2vec model ---\")\n",
    "d2v_model = Doc2Vec(docs, dm=0, min_count=2, vector_size=100, hs=0, negative=5, epochs=100, sample=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmodel_name = \"doc2vec_models/d2v_model.model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2v_model.save(fmodel_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2v_model = Doc2Vec.load(\"doc2vec_models/d2v_model.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- extracting learned embeddings and splitting them into training and testing sets\n",
      "training shape: (25000, 100)\n",
      "testing shape: (25000, 100)\n"
     ]
    }
   ],
   "source": [
    "print(\"--- extracting learned embeddings and splitting them into training and testing sets\")\n",
    "embeddings = d2v_model.dv.get_normed_vectors()\n",
    "train_embeddings, test_embeddings = np.split(embeddings, [25000]) # 25K because we have 25K reviews for training and 25K for testing\n",
    "\n",
    "print(\"training shape:\", train_embeddings.shape)\n",
    "print(\"testing shape:\", test_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- using document embeddings ---\n",
      "Accuracy: 0.90\n",
      "Std. Dev: 0.01\n"
     ]
    }
   ],
   "source": [
    "print(\"--- using document embeddings ---\")\n",
    "\n",
    "SVMD2V = SVMDoc2Vec()\n",
    "SVMD2V.train(train_embeddings, train_labels)\n",
    "SVMD2V.test(test_embeddings, test_labels)\n",
    "\n",
    "SVM_doc2vec_preds = SVMD2V.pred_labels\n",
    "\n",
    "print(f\"Accuracy: {SVMD2V.getAccuracy():.2f}\") \n",
    "print(f\"Std. Dev: {SVMD2V.getStdDeviation():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive-Bayes on IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 2) (25000, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "train_docs, test_docs = np.split(docs, [25000])\n",
    "\n",
    "print(train_docs.shape, test_docs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n",
      "25000\n"
     ]
    }
   ],
   "source": [
    "train_reviews = []\n",
    "for i,doc in enumerate(train_docs):\n",
    "    actual_doc = doc[0]\n",
    "    if train_labels[i]==1:\n",
    "        lbl = \"POS\"\n",
    "    else:\n",
    "        lbl = \"NEG\"\n",
    "    train_reviews.append((lbl, actual_doc))\n",
    "\n",
    "print(len(train_reviews))\n",
    "\n",
    "test_reviews = []\n",
    "for i,doc in enumerate(test_docs):\n",
    "    actual_doc = doc[0]\n",
    "    if test_labels[i]==1:\n",
    "        lbl = \"POS\"\n",
    "    else:\n",
    "        lbl = \"NEG\"\n",
    "    test_reviews.append((lbl, actual_doc))\n",
    "\n",
    "print(len(test_reviews))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8133\n",
      "Std. Dev: 0.009\n"
     ]
    }
   ],
   "source": [
    "NB_doc2vec = NaiveBayesText(smoothing=True,bigrams=False,trigrams=False,discard_closed_class=False)\n",
    "NB_doc2vec.train(train_reviews)\n",
    "NB_doc2vec.test(test_reviews)\n",
    "NB_doc2vec_preds=NB_doc2vec.predictions\n",
    "print(f\"Accuracy: {NB_doc2vec.getAccuracy():.4f}\") \n",
    "print(f\"Std. Dev: {NB_doc2vec.getStdDeviation():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results using Doc2Vec-Naive-Bayes are significant with respect to Doc2Vec-SVM\n"
     ]
    }
   ],
   "source": [
    "p_value=signTest.getSignificance(NB_doc2vec_preds, SVM_doc2vec_preds)\n",
    "significance = \"significant\" if p_value < 0.05 else \"not significant\"\n",
    "print(f\"results using Doc2Vec-Naive-Bayes are {significance} with respect to Doc2Vec-SVM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab\n",
    "from tsne import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing the data using PCA...\n",
      "Computing pairwise distances...\n",
      "Computing P-values for point 0 of 3000...\n",
      "Computing P-values for point 500 of 3000...\n"
     ]
    }
   ],
   "source": [
    "# Just visualizing 3000 training embeddings\n",
    "n_embed = 3000\n",
    "Y = tsne(train_embeddings[:n_embed,:], 2, 100, 20.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.scatter(Y[:, 0], Y[:, 1], 20, train_labels[:n_embed])\n",
    "pylab.xlabel(\"Principal component 1\")\n",
    "pylab.ylabel(\"Principal component 2\")\n",
    "pylab.legend()\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_embed):\n",
    "    if Y[i,0] > -80 and Y[i,0] < -70:\n",
    "        if Y[i,1] > -25 and Y[i,1] < 0:\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ids(ids):\n",
    "    pylab.scatter(Y[:, 0], Y[:, 1], 20, test_labels[:n_embed], alpha=0.15, s=200)\n",
    "    for id in ids:\n",
    "        pylab.scatter(Y[id, 0], Y[id, 1], 20, label=\"doc id=\"+str(id))\n",
    "    pylab.legend()\n",
    "    pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [84, 1791, 470]\n",
    "plot_ids(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels[:n_embed] \n",
    "\n",
    "neg_indices = (test_labels[:n_embed] == 0)\n",
    "pos_indices = (test_labels[:n_embed] == 1)\n",
    "\n",
    "true_positive = (test_labels[:n_embed]  == 1) * (pred_labels[:n_embed] == 1)\n",
    "true_negative = (test_labels[:n_embed]  == 0) * (pred_labels[:n_embed] == 0)\n",
    "false_positive = (test_labels[:n_embed]  == 0) * (pred_labels[:n_embed] == 1)\n",
    "false_negative = (test_labels[:n_embed]  == 1) * (pred_labels[:n_embed] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(num=None, figsize=(12, 12), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "\n",
    "plt.scatter(Y[neg_indices][:, 0], Y[neg_indices][:, 1], c='r', alpha=0.15, s=200, lw = 0,label=\"Negative reviews\")\n",
    "plt.scatter(Y[pos_indices][:, 0], Y[pos_indices][:, 1], c='g', alpha=0.15, s=200, lw = 0, label=\"Positive reviews\")\n",
    "\n",
    "#plt.scatter(Y[-200:][false_negative][:, 0], Y[-200:][false_negative][:, 1], c='g', label=\"False negative\")\n",
    "#plt.scatter(Y[-200:][false_positive][:, 0], Y[-200:][false_positive][:, 1], c='r', label=\"False positive\")\n",
    "\n",
    "plt.scatter(Y[false_negative][:, 0], Y[false_negative][:, 1], c='g', label=\"False negative\")\n",
    "plt.scatter(Y[false_positive][:, 0], Y[false_positive][:, 1], c='r', label=\"False positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_pred_indices = false_positive + false_negative\n",
    "good_pred_indices = true_positive + true_negatice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just visualizing 3000 testing embeddings in 3d\n",
    "n_embed = 3000\n",
    "Y3d = tsne(test_embeddings[:n_embed,:], 3, 100, 20.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(num=None, figsize=(12, 12), dpi=80, facecolor='w', edgecolor='k')\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(reduced_data_3d[neg_indices][:, 0], reduced_data_3d[neg_indices][:, 1], reduced_data_3d[neg_indices][:, 2], c='r', alpha=0.2, label=\"Negative reviews\")\n",
    "ax.scatter(reduced_data_3d[pos_indices][:, 0], reduced_data_3d[pos_indices][:, 1], reduced_data_3d[pos_indices][:, 2], c='g', alpha=0.2, label=\"Positive reviews\")\n",
    "\n",
    "ax.scatter(reduced_data_3d[-200:][bad_pred_indices][:, 0], reduced_data_3d[-200:][bad_pred_indices][:, 1], reduced_data_3d[-200:][bad_pred_indices][:, 2], c='k', label=\"Misclassified points\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
